{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California 2017 Fire recovery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString, MultiPolygon, asMultiPolygon, Polygon\n",
    "from shapely import wkb, wkt\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import wget\n",
    "from datetime import datetime\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import geocoder\n",
    "import geopy\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "# sys.path.insert(0, '/Users/jianglongli/Desktop/workbook/Freddie_project/PostGIS/gisfeaturecode_v7/')\n",
    "from mapping_utility_v2 import map_geopandas, map_AllHouses\n",
    "from mapping_utility_fire import map_geopandas_fire\n",
    "from python_postgis_talk_utility import transform_pd_to_gpd_general, transform_pd_to_gpd\n",
    "from cali_fire_utility import geomatch, readin_shapefile, timer, fire_postprocessing, create_fire_union\n",
    "from cali_fire_utility import download_and_create_shp, download_read_curent_fire\n",
    "from cali_fire_utility import map_fires, geocode, multigeocoding\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_cali = \"https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/current_year_fire_data/California/\"\n",
    "url_master = \"https://rmgsc.cr.usgs.gov\"\n",
    "folder_root = '/Users/jianglongli/Desktop/workbook/data/disaster_recovery'\n",
    "folder_sub = 'cali_fire'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in hve turned off file and try matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw hve count: 359266\n",
      "valid lat/lng count: 324931\n",
      "null lat/lng hve: 34335\n"
     ]
    }
   ],
   "source": [
    "hve_raw = pd.read_csv('%s/cali_turnedoff/cali_turned_off.csv' % folder_root, dtype={'zip': str})\n",
    "# hve_raw = pd.read_csv('%s/cali_turnedoff/cali_turned_off_geocoded.csv' % folder_root, dtype={'zip': str}) # geocoded\n",
    "print('raw hve count: %s' % hve_raw.shape[0])\n",
    "\n",
    "hve_raw.loc[:, 'long'] = hve_raw['long'].apply(lambda x: -x if x>0 else x)\n",
    "hve = hve_raw[hve_raw.lat.notnull()]\n",
    "print('valid lat/lng count: %s' % hve.shape[0])\n",
    "\n",
    "hve_null = hve_raw[hve_raw.lat.isnull()]\n",
    "hve_null.loc[:, 'address'] = hve_null.apply(lambda row: row['address'] + ',' + ' CA ' + row['zip'], axis=1)\n",
    "sample = hve_null.sample(100)\n",
    "print('null lat/lng hve: %s' % hve_null.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geocoding hve with missing lat/lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# hve_geocode = multigeocoding(hve_null, 60, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hve_geo = hve_geocode[hve_geocode.geocd.notnull()]\n",
    "# hve_geo.loc[:, 'lat'] = hve_geo.geocd.apply(lambda x: x[0])\n",
    "# hve_geo.loc[:, 'long'] = hve_geo.geocd.apply(lambda x: x[1])\n",
    "# hve_geo = hve_geo.drop('geocd', axis=1)\n",
    "# hve_comb = pd.concat([hve, hve_geo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %store -r hve_geo\n",
    "# hve_comb = pd.concat([hve, hve_geo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download shp files and create total geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## scraping start: 22:54:55 ##########\n",
      "totally 1558 zip files url parsed! 22:56:11\n",
      "\n",
      "########## check unzipped files: 22:56:11 ##########\n",
      "CPU times: user 48.6 s, sys: 1.36 s, total: 49.9 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gdf = download_and_create_shp(url_cali, url_master, folder_root, folder_sub, \n",
    "                              download_type='zip', unzip=True, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ring Self-intersection at or near point -122.29322609958997 38.368854461891438\n",
      "Ring Self-intersection at or near point -122.29322609958997 38.368854461891438\n",
      "Ring Self-intersection at or near point -122.29322609958997 38.368854461891438\n",
      "Ring Self-intersection at or near point -122.29322609959007 38.368854461891388\n",
      "Ring Self-intersection at or near point -122.29322609958997 38.368854461891438\n",
      "Ring Self-intersection at or near point -120.99716398229684 41.335605047406816\n",
      "Ring Self-intersection at or near point -120.03658782922585 37.62942306856656\n",
      "Ring Self-intersection at or near point -120.0365878176455 37.62942307763192\n",
      "Ring Self-intersection at or near point -120.0365878288182 37.62942306858718\n",
      "Ring Self-intersection at or near point -120.0365878176455 37.62942307763192\n",
      "Ring Self-intersection at or near point -120.0365878288182 37.62942306858718\n",
      "Ring Self-intersection at or near point -120.0365878176455 37.62942307763192\n",
      "Ring Self-intersection at or near point -123.62637115611462 41.663506352188669\n",
      "Ring Self-intersection at or near point -123.62637115661865 41.663506352467856\n",
      "Ring Self-intersection at or near point -123.62637115678682 41.66350635238868\n",
      "Ring Self-intersection at or near point -123.62637115678679 41.663506352388666\n",
      "Ring Self-intersection at or near point -123.62637115678682 41.66350635238868\n",
      "Ring Self-intersection at or near point -123.60333689991849 41.680863087551046\n",
      "Ring Self-intersection at or near point -123.60332303905004 41.680857959244463\n",
      "Ring Self-intersection at or near point -123.60333696144711 41.680863097617859\n",
      "Ring Self-intersection at or near point -123.60333696144711 41.680863097617859\n",
      "Ring Self-intersection at or near point -122.99133701416703 40.839094513373979\n",
      "Ring Self-intersection at or near point -123.01530993570498 40.847132661957772\n",
      "Ring Self-intersection at or near point -123.0152962275947 40.8471275290253\n",
      "Ring Self-intersection at or near point -118.44228809629483 36.26192899448435\n",
      "Ring Self-intersection at or near point -118.44252606725492 36.261927913500053\n",
      "Ring Self-intersection at or near point -118.44252606725492 36.261927913500053\n",
      "Ring Self-intersection at or near point -118.50576230688095 36.249524820912626\n",
      "Ring Self-intersection at or near point -118.50576230688095 36.249524820912626\n",
      "Ring Self-intersection at or near point -118.5157247613817 36.25783463971252\n",
      "Ring Self-intersection at or near point -118.46429821142441 36.273690597717412\n",
      "Ring Self-intersection at or near point -118.51572250339377 36.257717797724332\n",
      "Ring Self-intersection at or near point -118.44253001725455 36.261925334500532\n",
      "Ring Self-intersection at or near point -118.44253001725455 36.261925334500532\n",
      "Ring Self-intersection at or near point -118.44254244832675 36.261930493072548\n",
      "Ring Self-intersection at or near point -116.65094199122524 33.349003386705704\n",
      "Ring Self-intersection at or near point -119.47590904534599 37.23305714398029\n",
      "Ring Self-intersection at or near point -119.47590904534596 37.233057143980254\n",
      "Ring Self-intersection at or near point -119.47590904547052 37.233057143782986\n",
      "Ring Self-intersection at or near point -119.47590904547054 37.233057143783036\n",
      "Ring Self-intersection at or near point -119.47590904547054 37.233057143783036\n",
      "Ring Self-intersection at or near point -118.76747964186542 36.098198778406186\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.6861797120574 36.098492495477302\n",
      "Ring Self-intersection at or near point -118.62309738544023 36.155567593859949\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62309738544023 36.155567593859949\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62309738544023 36.155567593859949\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62310982625139 36.155572650763858\n",
      "Ring Self-intersection at or near point -118.62310976528993 36.155572691218381\n",
      "Ring Self-intersection at or near point -118.48626149985614 34.382014933587911\n",
      "Ring Self-intersection at or near point -118.48626149985614 34.382014933587911\n",
      "Ring Self-intersection at or near point -122.82748942730112 38.760035454902493\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.8275655924579 38.760033680402074\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.8275655924579 38.760033680402046\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402024\n",
      "Ring Self-intersection at or near point -122.82756559245793 38.760033680402074\n",
      "Ring Self-intersection at or near point -118.29648417593832 36.062487410793153\n",
      "Ring Self-intersection at or near point -118.29647179955711 36.062482342622403\n",
      "Ring Self-intersection at or near point -118.29647179956102 36.062482342887456\n",
      "Ring Self-intersection at or near point -119.59709647055307 37.56158280311378\n",
      "Ring Self-intersection at or near point -119.59712195153877 37.561602081491074\n",
      "Ring Self-intersection at or near point -119.7839088545018 38.327829127976187\n",
      "Ring Self-intersection at or near point -123.69211231874129 41.842163761857243\n"
     ]
    }
   ],
   "source": [
    "gdf = fire_postprocessing(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 1s, sys: 14.5 s, total: 23min 15s\n",
      "Wall time: 13min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gdf_union = create_fire_union(gdf, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:12:05\n",
      "CPU times: user 18min 33s, sys: 2.08 s, total: 18min 35s\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(timer())\n",
    "result = geomatch(hve, gdf_union, 'firename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**download current fire shapefile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_current = download_read_curent_fire(folder_root)\n",
    "gdf_current_ca = gdf_current[gdf_current.state == 'CA']\n",
    "gdf_current_ca = fire_postprocessing(gdf_current_ca)\n",
    "result_current = geomatch(hve, gdf_current_ca, 'firename', ['firename', 'geometry', 'perdattime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fire impact reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **fire this year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = result.firename.value_counts()\n",
    "summary = pd.concat([counts.rename('count'), gdf_union.set_index('firename')], axis=1, join='inner')\n",
    "summary = summary.reset_index().rename(columns={'index': 'firename'})\n",
    "summary = transform_pd_to_gpd(summary, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary.to_csv(folder_root + '/' + 'fire_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_geopandas_fire(summary, ckeep=['firename', 'geometry', 'count'], clabel='firename', \n",
    "              cpop=['firename', 'count'], saveTo='./', saveName='2017fire', saveOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hve_onfire = result[result.firename.notnull()]\n",
    "hve_onfire.drop('geometry', axis=1).to_csv('/Users/jianglongli/Desktop/workbook/data/hve_onfire.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **current fire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hve_onfire_current = result_current[result_current.firename.notnull()]\n",
    "summary_crrt = hve_onfire_current.firename.value_counts().rename('count')\n",
    "summary_crrt = pd.concat([summary_crrt, gdf_current_ca[['firename', 'gisacres', 'geometry']].set_index('firename')], \n",
    "         axis=1, join='inner').reset_index().rename(columns={'index': 'firename'})\n",
    "summary_crrt = transform_pd_to_gpd(summary_crrt, geometry='geometry')\n",
    "summary_crrt.to_csv('/Users/jianglongli/Desktop/workbook/data/summary_crrt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_geopandas_fire(summary_crrt, ckeep=['firename', 'geometry', 'count'], clabel='firename', \n",
    "              cpop=['firename', 'count'], saveTo='./', saveName='current_fire', saveOnly=True)\n",
    "\n",
    "map_geopandas_fire(gdf[gdf.firename == 'ABNEY'], ckeep=['firename', 'geometry'], clabel='firename', \n",
    "              cpop=['firename'], saveTo='./', saveName='before_union', saveOnly=True)\n",
    "\n",
    "map_geopandas_fire(gdf_union[gdf_union.firename == 'ABNEY'], ckeep=['firename', 'geometry'], clabel='firename', \n",
    "              cpop=['firename'], saveTo='./', saveName='after_union', saveOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hve_onfire_current.drop('geometry', axis=1).to_csv('/Users/jianglongli/Desktop/workbook/data/hve_onfire_current.csv', \n",
    "                                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with zipcode & county shapfiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_tiger_shp(url_file, folder_create):\n",
    "#     folder_create = '%s/zipshpfile' % folder_root\n",
    "    if not os.path.exists(folder_create):\n",
    "        os.mkdir(folder_create)\n",
    "    zipfile = wget.download(url_file, \n",
    "                  out=folder_create)\n",
    "    with zipfile.ZipFile(zfile, \"r\") as zip_ref: \n",
    "        zip_ref.extractall(path=folder_create) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jianglongli/Desktop/workbook/data//tl_2017_us_zcta510.zip'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_create = '%s/zipshpfile' % folder_root\n",
    "if not os.path.exists(folder_create):\n",
    "    os.mkdir(folder_create)\n",
    "zipfile = wget.download('ftp://ftp2.census.gov/geo/tiger/TIGER2017/ZCTA5/tl_2017_us_zcta510.zip', \n",
    "              out=folder_create)\n",
    "with zipfile.ZipFile(zfile, \"r\") as zip_ref: \n",
    "    zip_ref.extractall(path=folder_create) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_create = '%s/cntyshpfile' % folder_root\n",
    "if not os.path.exists(folder_create):\n",
    "    os.mkdir(folder_create)\n",
    "zipfile = wget.download('ftp://ftp2.census.gov/geo/tiger/TIGER2017/COUNTY/tl_2017_us_county.zip', \n",
    "              out=folder_create)\n",
    "with zipfile.ZipFile(cntyfile, \"r\") as zip_ref: \n",
    "    zip_ref.extractall(path=folder_create) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 38s, sys: 3.62 s, total: 8min 42s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gdfzip = readin_shapefile('%s/zipshpfile/tl_2017_us_zcta510.shp' % folder_root)\n",
    "gdfcnty = readin_shapefile('%s/cntyshpfile/tl_2017_us_county.shp' % folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 59.7 ms, total: 8.32 s\n",
      "Wall time: 8.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_zip = gpd.sjoin(gdf_union, gdfzip, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 23.9 ms, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_cnty = gpd.sjoin(gdf_union, gdfcnty, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare fires map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create houses data for mapping\n",
    "houses = result.drop_duplicates(subset=['zip', 'address'])\n",
    "houses.loc[:,'color'] = np.where(houses.firename.isnull(), 'grey', 'red')\n",
    "\n",
    "# create all impacted counties, zips\n",
    "fire_select = gdf_union\n",
    "county_select = gdfcnty[gdfcnty.geoid.isin(result_cnty.geoid.unique())]\n",
    "zip_select = gdfzip[gdfzip.geoid10.isin(result_zip.geoid10.unique())]\n",
    "\n",
    "# create hve impacted fires data\n",
    "gdf_hvefire = gdf_union[gdf_union.firename.isin(result.firename.unique())]\n",
    "\n",
    "# create FEMA counties\n",
    "fema_counties = ['Butte', 'Lake', 'Mendocino', 'Napa', 'Nevada', 'Sonoma', 'Yuba']\n",
    "gdf_fema = gdfcnty[gdfcnty.name.isin(fema_counties) & (gdfcnty.statefp == '06')]\n",
    "\n",
    "# get FEMA turned off zips\n",
    "zipall = pd.read_excel('/Users/jianglongli/Downloads/Copy of Wildfire_zip_code_1017_2017.xls')\n",
    "zipall = zipall[zipall.COUNTY_NAME != 'ORANGE']\n",
    "zipall.loc[:, 'zipcode'] = zipall.zipcode.astype(str)\n",
    "gdf_femazips = gdfzip[gdfzip.geoid10.isin(zipall.zipcode.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfs = {'all fires': (fire_select, 'firename', '#ff0000') # red \n",
    "       ,'all impacted counties': (county_select, 'namelsad', '#f7f327') # yellow\n",
    "       ,'all impacted zipcode': (zip_select, 'geoid10', '#d1f9f2') # blue\n",
    "       ,'FEMA counties': (gdf_fema, 'namelsad', '#00ff72')  # purple\n",
    "       ,'FEMA zips': (gdf_femazips, 'geoid10', '#9a999b')  # grey\n",
    "       ,'HVE impacted fires': (gdf_hvefire, 'firename', '#ff0000')} # red\n",
    "\n",
    "map_fires(gdfs, saveName='all_fire_5000', saveOnly=True, saveTo='%s/maps' % folder_root, houses=houses.sample(5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "+ **GeoMAC data, part of USGS, this data provides file polygons**: https://www.geomac.gov/index.shtml \n",
    "    - shapefile: https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/\n",
    "    - data attribute definition: \n",
    "        * https://www.nwcg.gov/sites/default/files/stds/WildlandFirePerimeters_definition.pdf\n",
    "        * https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/historic_fire_data/perimeters_dd83_METADATA.htm\n",
    "    - curent file perimeter methodology: https://www.geomac.gov/viewer/help/perimeters_active.html    \n",
    "    - GeoMAC map viewer help and documentation:https://www.geomac.gov/viewer/help/Help.html\n",
    "    - a 2008 publication about GeoMAC: https://pubs.usgs.gov/ds/612/pdf/ds612.pdf\n",
    "    - a 2008 GeoMAC user guide: https://webarchive.library.unt.edu/eot2008/20080916004656/http://geomac.gov/pdf/UsersGuide/GeoMAC_UG.pdf\n",
    "\n",
    "\n",
    "+ **GeoMAC data source from NIFC:** https://www.geomac.gov/about.shtml\n",
    "\n",
    "\n",
    "+ **NIFC raw data FTP site:** http://ftp.nifc.gov/\n",
    "\n",
    "\n",
    "+ **USGS**: https://www.usgs.gov/centers/gecsc\n",
    "\n",
    "\n",
    "+ **Data Basin view of GeoMAC**: https://databasin.org/datasets/6ed18e2a72e74b0d81e14c93d5b46f07\n",
    "\n",
    "\n",
    "+ **NASA Fire Information for Resource Management System (FIRMS), mostly point data, near real time**: https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms\n",
    "\n",
    "\n",
    "+ **CA fire org, has google map fire range, but not sure how to get the shapefile**: http://www.calfire.ca.gov/general/firemaps\n",
    "    - FRAP program from Cal Fire also has fire perimeter data: http://frap.fire.ca.gov/data/frapgisdata-sw-fireperimeters_download\n",
    "    \n",
    "    \n",
    "+ **KML file tutorial**: https://developers.google.com/kml/documentation/kml_tut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "**GeoMAC fire perimeters:**\n",
    "his layer contains fire perimeters that are submitted to GeoMAC by field offices. The fire perimeters are updated every one or two days, as the data is made available. If we have received no new data, the \"expired\" layer is not replaced. The layer is replaced as soon as we receive an updated file. Perimeters are usually collected on a daily basis for large fires that are growing. However, there may be gaps in daily coverage.\n",
    "\n",
    "The GeoMAC team attributes the perimeters using the IRWIN (Integrated Reporting of Wildland-Fire Information) system.\n",
    "\n",
    "Perimeters are collected in the field by a variety of means, including infrared flights, and by using a GPS unit to map the perimeter. Please NOTE: GeoMAC only displays perimeter data as they are submitted by field offices. Since data are not received for all fires, you may not be able to view perimeters for every fire.\n",
    "\n",
    "Perimeter data displayed in and delivered by the Geomac application is not the final or official perimeter for any incident and is provided for informational purposes only. The final official perimeter should be obtained from the host unit which can be determined by looking at the Unit Id for any specific fire. The host unit is responsible for producing official and final perimeters for all incidents in their jurisdiction.\n",
    "\n",
    "\n",
    "**Cal Fire**: \n",
    "As part of the California Fire Plan, the Fire and Resource Assessment Program (FRAP) compiles fire perimeters and has established an on-going fire perimeter data capture process in order to update vegetative fuel rank maps. CAL FIRE/FRAP, the USDA Forest Service Region 5 Remote Sensing Lab, the Bureau of Land Management, and the National Park Service jointly develop the comprehensive fire perimeter GIS layer for public and private lands throughout California.\n",
    "\n",
    "The fire perimeter database represents the most complete digital record of fire perimeters in California. However it is still incomplete in many respects. Fire perimeter database users must exercise caution to avoid inaccurate or erroneous conclusions. For more information on potential errors and their source please review the methodology section of these pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Web Scraping reflection\n",
    "+ try scrapy (scrapy vs beautifulsoup): https://blog.michaelyin.info/2017/08/10/scrapy-tutorial-1-scrapy-vs-beautiful-soup/\n",
    "\n",
    "+ scrapy is a framework: https://hexfox.com/p/scrapy-vs-beautifulsoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
